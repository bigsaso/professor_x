{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1, l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_create_train_test(test_split):\n",
    "    \"\"\"\n",
    "    test_split (input): The percentage of data that will be used to test\n",
    "    \"\"\"\n",
    "    # Specify the path to your csv files\n",
    "    csv_files = glob.glob('trial/*.csv')\n",
    "\n",
    "    # List comprehension to load all csv files into dataframe\n",
    "    dataframes = [pd.read_csv(file) for file in csv_files]\n",
    "    \n",
    "    # Concatenate all dataframes into one\n",
    "    combined_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Shuffle the dataset to ensure a good mix of data points\n",
    "    combined_dataframe = shuffle(combined_dataframe, random_state=42)\n",
    "\n",
    "    # Remove sample count\n",
    "    combined_dataframe.drop(['Sample Count'], axis=1, inplace=True)\n",
    "\n",
    "    X = combined_dataframe.drop(['Movement', axis=1])\n",
    "    y = combined_dataframe.Movement\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    y = to_categorical(y)\n",
    "\n",
    "    # Splitting the dataset into the Training set and Testing set. Stratify should keep all classes of movement balanced\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_split, random_state=42, stratify=y)\n",
    "\n",
    "    # Feature scaling because we don't want one indepedent variable dominating the other and it makes computation easy\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    return combined_dataframe, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, X_train, X_test, y_train, y_test = read_csv_create_train_test(test_split=0.3)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # Initializing the ANN\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # Adding the input layer\n",
    "    classifier.add(Dense(units=X_train.shape[1], activation='relu', input_dim=X_train.shape[1], kernel_regularizer=l1(0.01)))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(units=128, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "\n",
    "    # Adding the output layer\n",
    "    classifier.add(Dense(units=4, activation='softmax'))\n",
    "\n",
    "    # Compiling the ANN\n",
    "    adam = Adam(learning_rate=0.001)\n",
    "    classifier.compile(optimizer=adam, loss='categorical_crossentropy', metricxs=['accuracy'])\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "\n",
    "# Create and EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Training the ANN on the training set\n",
    "model.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs=500, callbacks=[early_stopping])\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a confusion matrix to visualize how accurate the model is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert probabilities to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Convert one-hot encoded y_test to class labels\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Making the confusion matrix\n",
    "cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(cm)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "p = sns.heatmap(pd.Dataframe(cm), annot=True, cmap=\"YlGnBu\", fmt='g')\n",
    "plt.title(\"Confusion matrix\", y=1.1)\n",
    "plt.ylabel(\"Actual label\")\n",
    "plt.xlabel(\"Predicted label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "n_classes = y_test.shape[1]\n",
    "frp = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plotting the ROC curce\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red'])\n",
    "for i, color in zip(rage(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "    label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "    ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0,1], [0,1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the Keras model\n",
    "keras_model = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
